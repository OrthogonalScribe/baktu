# Introduction

<div class='warning'>

**Work in progress:**

At the moment `baktu` is a work-in-progress proof of concept. It can currently create and manipulate repositories, as well as create initial snapshots with intra-snapshot file deduplication. Full testing and further feature development (including subsequent snapshot creation and FUSE mounting) are pending implementation of more extensive snapshot reading code.

`baktu` is very much under development and not yet productized. Do not use it on any data that you have not backed up.
</div>

[`baktu`](https://github.com/OrthogonalScribe/baktu) is an [rsnapshot](https://rsnapshot.org/)-inspired backup tool. It features a [git](https://git-scm.com/)-inspired workflow, creates file-level-deduplicated snapshots of directories and stores them in repositories. It is a personal scratch-own-itch project driven by the following requirements:

* **Support "infinite" retention:** the main driver of some of the following features. `baktu` aims to minimize unnecessary storage costs to enable much longer backup repository lifetimes for scenarios where the amount of new data is relatively limited
    * **Minimize inode cost per snapshot:** [history intervals](repositories/v1/index.md#history-intervals) are used to make the inode cost per snapshot proportional to the number of files changed, instead of to the number of directories in the *source dataset* (the set of files and directories to be snapshotted). For source datasets with large numbers of directories, this significantly increases the number of snapshots that can be saved on ext4 file systems
    * **File-level deduplication:** to support source datasets with large amounts of duplicated data, as well as reduce the storage costs incurred by snapshots after major file reorganization, `baktu` detects duplicate data across the current source dataset, as well as the entire backup repository, including all *sites* (see below) and the snapshots in them
    * **Deduplication support across multiple source datasets:** multiple machines might have semi-synchronized datasets that all need to be backed up. Deduplicating the data across those is a major win in terms of storage requirements, which is why `baktu` repositories contain a set of [sites](repositories/v1/index.md#sites), somewhat similar to [git branches](https://git-scm.com/book/en/v2/Git-Branching-Branches-in-a-Nutshell) (although the former are currently a set of snapshot sequences and the latter a [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph)). New files are deduplicated across all sites when added to the repository
* **Record more extensive metadata:** `baktu` fetches and records metadata from several sources for each file:
    * extended attributes, including those in the [`trusted` namespace](https://www.mankier.com/7/xattr#Description-Trusted_extended_attributes)
        * this requires giving [`CAP_SYS_ADMIN`](https://www.mankier.com/7/capabilities#Description-Capabilities_list) to `baktu` or a helper program (see [Installation](installation.md))
    * [`statx(2)`](https://www.mankier.com/2/statx), notably including file creation time
    * inode flags from the [`FS_IOC_GETFLAGS` ioctl](https://www.mankier.com/2/ioctl_iflags) used by `lsattr(1)`
        * `FS_IOC_FSGETXATTR` is not currently used
* **Minimize risk and impact of data corruption:** `baktu` trades possible gains in storage efficiency and design elegance for a simpler storage approach. This aims to reduce the blast radius of data corruption, as well as lower the barrier for and increase the chances of data recovery. This is done via, among others:
    * **File-level instead of block-level deduplication:** this simplifies the data formats and algorithms used, ideally preventing bit flips from affecting more than the files that contain them (and their duplicates), compared to experiences with some block-level deduplicating backup tools. However, this has downsides for scenarios that include a lot of small data changes in large files (VM images and similar)
    * **[KISS](https://en.wikipedia.org/wiki/KISS_principle) repository design:** `baktu` repositories are designed to stay as close as possible to the source dataset within the limits of the requirements, even at the cost of performance or elegance. The aim is to provide [graceful degradation](https://en.wikipedia.org/wiki/Graceful_degradation), allowing for things like exploration and file recovery to be [doable with nothing more than standard Unix command line tools](repositories/v1/access-with-unix-tools.md) like `grep`, `find`, `less` and shell globs
    * **Meta-data stored in mostly human-readable files:** all file metadata is stored in [Binary Record-Jar](repositories/v1/index.md#binary-record-jar-format) formatted files in the same directory as the files they reference. This is human-readable, except for a few of the payloads. This [sidecar file](https://en.wikipedia.org/wiki/Sidecar_file) approach allows the repository to survive transformations that would strip that metadata from the files within it, and is the chosen approach to store metadata for multiple file duplicates backed by a single data file (cf. `rsync --link-dest` trade-offs). In addition, this [*textualizer*](http://www.catb.org/esr/writings/taoup/html/ch06s02.html#id2914758)-like aspect of the backup process lowers the barrier to metadata exploration and recovery for a wider audience
* **Provide simple and standardized method for accessing backed up data:** `baktu` aims to expose snapshots as regular directories, but more importantly as close as possible to the source dataset. The (currently under development) `baktu mount` command will create a [FUSE](https://en.wikipedia.org/wiki/Filesystem_in_Userspace) mount of the specified snapshot, emulating as much of the file metadata as allowed by the FUSE interface and Rust libraries used. Further metadata can be manually inspected directly in the repository, but future possibilities include an `LD_PRELOAD` shared object to emulate more of the metadata, research into multi-snapshot mounting (vs inode collision), and `baktu` subcommands for somewhat less manual metadata access in the interim. A more remote possibility might be expanding the capabilities of the Rust FUSE libraries used, and the FUSE interface itself as needed

[self note: /etc/ld.so.preload can be used for system-wide deployment, also without the LD_PRELOAD limitations referenced in https://superuser.com/questions/1183037/what-is-does-ld-so-preload-do/1183252#1183252, example at https://www.baeldung.com/linux/ld_preload-trick-what-is#alternative-to-ldpreload]::

Other requirements that emerged during the development process include:

* **Support all valid ext4 filenames:** as a backup tool, `baktu` might be used in scenarios with datasets including non-Unicode or outright adversarial filenames, so it aims to support the full range of filenames allowed by ext4 (including any byte except `NULL` and `/`) for all features of the tool (including include and exclude configuration)
* **Support more flexible inclusion and exclusion workflows:** `baktu` has support for explicit include and exclude path sets per site via [NSV](repositories/v1/index.md#null-separated-values-format) files, as well as [CACHEDIR.TAG directories and files marked with the `d` attribute](quick-start.md#other-exclusion-criteria)
* **Minimize possibilities for user error:**
    * **Configuration files over CLI switches:** despite being a command line tool, `baktu` errs on the side of storing as much of the configuration as possible in its repositories. This aims to decrease the risk of snapshot-to-snapshot configuration inconsistency by reducing the number of command line arguments needed, and to nudge the user toward more extensively documented configuration. This comes at the cost of flexibility in some use case scenarios, but was deemed preferable
    * **Guide user during normal workflow:** `baktu` features extensive and configurable logging, which helps with diagnosing issues during backup, as well as guiding the user to workflow adjustments that they may have otherwise not discovered. For example, `baktu` detects valid [CACHEDIR.TAG](https://bford.info/cachedir/) directories (such as [`cargo` build dirs](https://internals.rust-lang.org/t/pre-rfc-put-cachedir-tag-into-target/12262) and [registries](https://github.com/rust-lang/cargo/pull/10553)), and suggests excluding them and how to do so
